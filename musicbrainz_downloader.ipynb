{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicBrainz artist lookup\n",
    "\n",
    "To see this analysis live, check out my article [\"Analyzing Last.fm Listening History\"](http://geoffboeing.com/2016/05/analyzing-lastfm-history/)\n",
    "\n",
    "Get artist information, including place name, for each artist that has a music brainz id in my data set generated by the [lastfm_downloader](lastfm_downloader.ipynb). Script uses a local JSON cache to store artist and area details from the music brainz api, by unique id. If any id appears in the cache, the script uses the local version instead of requesting from the api, making the process very fast.\n",
    "\n",
    "Documentation:\n",
    " - Web service: https://wiki.musicbrainz.org/Development/XML_Web_Service/Version_2/Search\n",
    " - Artist entities: https://musicbrainz.org/doc/Artist\n",
    " - Area entities: https://musicbrainz.org/doc/Area\n",
    "\n",
    "Sample queries:\n",
    " - Artist: https://musicbrainz.org/ws/2/artist/d4659efb-b8eb-4f03-95e9-f69ce35967a9\n",
    " - Area: https://musicbrainz.org/ws/2/area/0a70f24b-1263-4341-8d70-17b8df84154f?inc=area-rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, requests, time, json, os.path\n",
    "import logging as lg, datetime as dt\n",
    "from keys import mb_user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_standard = 1.1\n",
    "pause_exceeded_rate = 2\n",
    "\n",
    "# where to save the csv output\n",
    "csv_filename = 'data/mb.csv'\n",
    "\n",
    "# configure URLs and user-agent header\n",
    "artist_name_url = 'https://musicbrainz.org/ws/2/artist/?query=artist:{}&fmt=json'\n",
    "artist_id_url = 'https://musicbrainz.org/ws/2/artist/{}?fmt=json'\n",
    "area_id_url = 'https://musicbrainz.org/ws/2/area/{}?inc=area-rels&fmt=json'\n",
    "headers = {'User-Agent':mb_user_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure local caching\n",
    "area_cache_filename = 'data/area_cache.js'\n",
    "artist_cache_filename = 'data/artist_cache.js'\n",
    "cache_save_frequency = 10\n",
    "area_requests_count = 0\n",
    "artist_requests_count = 0\n",
    "area_cache = json.load(open(area_cache_filename)) if os.path.isfile(area_cache_filename) else {}\n",
    "artist_cache = json.load(open(artist_cache_filename)) if os.path.isfile(artist_cache_filename) else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logger to capture progress\n",
    "log = lg.getLogger('mb')\n",
    "if not getattr(log, 'handler_set', None):\n",
    "    todays_date = dt.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    log_filename = 'logs/mb_{}.log'.format(todays_date)\n",
    "    handler = lg.FileHandler(log_filename, encoding='utf-8')\n",
    "    formatter = lg.Formatter('%(asctime)s %(levelname)s %(name)s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    log.addHandler(handler)\n",
    "    log.setLevel(lg.INFO)\n",
    "    log.handler_set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a http request to musicbrainz api and return the result\n",
    "def make_request(url, headers=headers, attempt_count=1):\n",
    "    \n",
    "    global pause_standard\n",
    "    \n",
    "    time.sleep(pause_standard)\n",
    "    log.info('request: {}'.format(url))\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "    except Exception as e:\n",
    "        log.error('requests.get failed: {} {} {}'.format(type(e), e, response.json()))\n",
    "        \n",
    "    if response.status_code == 200: #if status OK\n",
    "        return {'status_code':response.status_code, 'json':response.json()}\n",
    "    \n",
    "    elif response.status_code == 503: #if status error (server busy or rate limit exceeded)\n",
    "        try:\n",
    "            if 'exceeding the allowable rate limit' in response.json()['error']:\n",
    "                #pause_standard = pause_standard + 0.1\n",
    "                log.warning('exceeded allowable rate limit, pause_standard is now {} seconds'.format(pause_standard))\n",
    "                log.warning('details: {}'.format(response.json()))\n",
    "                time.sleep(pause_exceeded_rate)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        next_attempt_count = attempt_count + 1\n",
    "        log.warning('request failed with status_code 503, so we will try it again with attempt #{}'.format(next_attempt_count))\n",
    "        return make_request(url, attempt_count=next_attempt_count)\n",
    "    \n",
    "    else: #if other status code, display info and return None for caller to handle\n",
    "        log.error('make_request failed: status_code {} {}'.format(response.status_code, response.json()))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the musicbrainz api for an artist's name and return the resulting id\n",
    "def get_artist_id_by_name(name):\n",
    "    response = make_request(artist_name_url.format(name))\n",
    "    try:\n",
    "        if response is not None:\n",
    "            result = response['json']\n",
    "            artist_id = result['artists'][0]['id']\n",
    "            return artist_id\n",
    "    except:\n",
    "        log.error('get_artist_id_by_name error: {}'.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the details of an artist from the API response\n",
    "def extract_artist_details_from_response(response):\n",
    "    try:\n",
    "        if response is not None:\n",
    "            result = response['json']\n",
    "            artist_details = {'id':result['id'],\n",
    "                              'name':result['name'],            \n",
    "                              'type':result['type'],\n",
    "                              'gender':result['gender'],\n",
    "                              'country':result['country'],\n",
    "                              'begin_date':None,\n",
    "                              'end_date':None,\n",
    "                              'area_id':None,\n",
    "                              'area_name':None,\n",
    "                              'begin_area_id':None,\n",
    "                              'begin_area_name':None,\n",
    "                              'place_id':None,\n",
    "                              'place':None}\n",
    "\n",
    "            if result['life-span'] is not None and 'begin' in result['life-span'] and 'end' in result['life-span']:\n",
    "                artist_details['begin_date'] = result['life-span']['begin']\n",
    "                artist_details['end_date'] = result['life-span']['end']\n",
    "            if result['area'] is not None and 'id' in result['area'] and 'name' in result['area']:\n",
    "                artist_details['area_id'] = result['area']['id']\n",
    "                artist_details['area_name'] = result['area']['name']\n",
    "            if result['begin_area'] is not None and 'id' in result['begin_area'] and 'name' in result['begin_area']:\n",
    "                artist_details['begin_area_id'] = result['begin_area']['id']\n",
    "                artist_details['begin_area_name'] = result['begin_area']['name']\n",
    "            \n",
    "            # populate place with begin_area_name if it's not null, else area_name if it's not null, else None\n",
    "            if artist_details['begin_area_name'] is not None:\n",
    "                artist_details['place'] = artist_details['begin_area_name']\n",
    "                artist_details['place_id'] = artist_details['begin_area_id']\n",
    "            elif artist_details['area_name'] is not None:\n",
    "                artist_details['place'] = artist_details['area_name']\n",
    "                artist_details['place_id'] = artist_details['area_id']\n",
    "            \n",
    "            return artist_details\n",
    "    \n",
    "    except:\n",
    "        log.error('get_artist_by_id error: {}'.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an artist object from the musicbrainz api by the musicbrainz artist id\n",
    "def get_artist_by_id(artist_id):\n",
    "    \n",
    "    global artist_cache, artist_requests_count\n",
    "    \n",
    "    # first, get the artist details either from the cache or from the API\n",
    "    if artist_id in artist_cache:\n",
    "        # if we've looked up this ID before, get it from the cache\n",
    "        log.info('retrieving artist details from cache for ID {}'.format(artist_id))\n",
    "        artist_details = artist_cache[artist_id]\n",
    "    else:\n",
    "        # if we haven't looked up this ID before, look it up from API now\n",
    "        response = make_request(artist_id_url.format(artist_id))\n",
    "        artist_details = extract_artist_details_from_response(response)\n",
    "        \n",
    "        # add this artist to the cache so we don't have to ask the API for it again\n",
    "        artist_cache[artist_id] = artist_details \n",
    "        log.info('adding artist details to cache for ID {}'.format(artist_id))\n",
    "        \n",
    "        # save the artist cache to disk once per every cache_save_frequency API requests\n",
    "        artist_requests_count += 1\n",
    "        if artist_requests_count % cache_save_frequency == 0: save_cache_to_disk(artist_cache, artist_cache_filename)\n",
    "    \n",
    "    # now that we have the artist details...\n",
    "    return artist_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of artist details and place info from a list of artist IDs\n",
    "def make_artists_df(artist_ids, row_labels=None, df=None, csv_save_frequency=100):\n",
    "    \n",
    "    # create a list of row labels if caller didn't pass one in\n",
    "    if row_labels is None:\n",
    "        row_labels = range(len(artist_ids))\n",
    "    \n",
    "    # create a new dataframe if caller didn't pass an existing one in\n",
    "    cols = ['id', 'name', 'type', 'gender', 'country', 'begin_date', 'end_date', \n",
    "            'begin_area_id', 'begin_area_name', 'area_id', 'area_name', 'place_id', 'place']\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for artist_id, n in zip(artist_ids, row_labels):\n",
    "        try:\n",
    "            # get the artist info object\n",
    "            artist = get_artist_by_id(artist_id)\n",
    "\n",
    "            # create (or update) a df row containing the data from this artist object\n",
    "            df.loc[n] = [ artist[col] for col in cols ]\n",
    "            log.info('successfully got artist details #{:,}: artist_id={}'.format(n, artist_id))\n",
    "            \n",
    "            # save csv dataset to disk once per every csv_save_frequency rows\n",
    "            if n % csv_save_frequency == 0: df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "            \n",
    "        except Exception as e:\n",
    "            log.error('row #{} failed: {}'.format(n, e))\n",
    "            pass\n",
    "    \n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "    finish_time = time.time()\n",
    "    message = 'processed {:,} artists in {:,} seconds and saved csv'.format(len(artist_ids), round(finish_time-start_time, 2))\n",
    "    log.info(message)\n",
    "    print(message)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the details of an area object from the API response\n",
    "def extract_area_details_from_response(response):\n",
    "    area_details = {}\n",
    "    try:\n",
    "        area_details['name'] = response['json']['name']\n",
    "        if 'relations' in response['json']:\n",
    "            for relation in response['json']['relations']:\n",
    "                if relation['direction']=='backward' and relation['type']=='part of':\n",
    "                    area_details['parent_id'] = relation['area']['id']\n",
    "                    area_details['parent_name'] = relation['area']['name']\n",
    "        else:\n",
    "            log.warning('area returned no relations: {}'.format(result))\n",
    "        return area_details\n",
    "    except Exception as e:\n",
    "        log.error('extract_area_details_from_response failed: {}'.format(response))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get details of an 'area' from the musicbrainz api by area id\n",
    "def get_area(area_id, full_area_str=''):\n",
    "    \n",
    "    global area_cache, area_requests_count\n",
    "    \n",
    "    # first, get the area details either from the cache or from the API\n",
    "    if area_id in area_cache:\n",
    "        # if we've looked up this ID before, get it from the cache\n",
    "        log.info('retrieving area details from cache for ID {}'.format(area_id))\n",
    "        area_details = area_cache[area_id]\n",
    "    else:\n",
    "        # if we haven't looked up this ID before, look it up from API now\n",
    "        response = make_request(area_id_url.format(area_id))\n",
    "        area_details = extract_area_details_from_response(response)\n",
    "        \n",
    "        # add this area to the cache so we don't have to ask the API for it again\n",
    "        area_cache[area_id] = area_details \n",
    "        log.info('adding area details to cache for ID {}'.format(area_id))\n",
    "        \n",
    "        # save the area cache to disk once per every cache_save_frequency API requests\n",
    "        area_requests_count += 1\n",
    "        if area_requests_count % cache_save_frequency == 0: save_cache_to_disk(area_cache, area_cache_filename)\n",
    "    \n",
    "    # now that we have the area details...\n",
    "    try:\n",
    "        if full_area_str == '': \n",
    "            full_area_str = area_details['name']\n",
    "        if 'parent_name' in area_details and 'parent_id' in area_details:\n",
    "            full_area_str = '{}, {}'.format(full_area_str, area_details['parent_name'])\n",
    "            return area_details['parent_id'], full_area_str #recursively get parent's details\n",
    "        else:\n",
    "            # if no parents exist, we're done\n",
    "            return None, full_area_str\n",
    "    except Exception as e:\n",
    "        log.error('get_area error: {}'.format(e)) \n",
    "        return None, full_area_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a full name from an area ID\n",
    "# recursively traverse the API, getting coarser-grained place details each time until top-level country\n",
    "def get_place_full_name_by_area_id(area_id):\n",
    "    area_name=''\n",
    "    while area_id is not None:\n",
    "        area_id, area_name = get_area(area_id, area_name)\n",
    "    return area_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a list of place IDs and return a dict linking each to its constructed full name\n",
    "def get_place_full(unique_place_ids):\n",
    "    start_time = time.time()\n",
    "    message = 'we will attempt to get place full names for {:,} place IDs'.format(len(unique_place_ids))\n",
    "    log.info(message)\n",
    "    print(message)\n",
    "    \n",
    "    place_ids_names = {}\n",
    "    for place_id, n in zip(unique_place_ids, range(len(unique_place_ids))):\n",
    "        try:\n",
    "            place_name = get_place_full_name_by_area_id(place_id)\n",
    "        except:\n",
    "            place_name = None\n",
    "        place_ids_names[place_id] = place_name\n",
    "        log.info('successfully created place #{:,}: \"{}\" from place ID \"{}\"'.format(n + 1, place_name, place_id))\n",
    "    \n",
    "    message = 'finished getting place full names from place IDs in {:.2f} seconds'.format(time.time()-start_time)\n",
    "    log.info(message)\n",
    "    print(message)\n",
    "    return place_ids_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find place id in dict (created by get_place_full) and return its constructed full name\n",
    "def get_place_full_from_dict(place_id):\n",
    "    try:\n",
    "        return place_ids_names[place_id]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save local cache object in memory to disk as JSON\n",
    "def save_cache_to_disk(cache, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as cache_file:\n",
    "        cache_file.write(json.dumps(cache))\n",
    "    log.info('saved {:,} cached items to {}'.format(len(cache.keys()), filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it with a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo test finished in 2.31 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Brixton, Lambeth, London, England, United Kingdom'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where is david bowie from?\n",
    "name = 'david bowie'\n",
    "start_time = time.time()\n",
    "artist_id = get_artist_id_by_name(name)\n",
    "artist = get_artist_by_id(artist_id)\n",
    "artist['place_full'] = get_place_full_name_by_area_id(artist['place_id'])\n",
    "message = 'demo test finished in {:.2f} seconds'.format(time.time()-start_time)\n",
    "log.info(message)\n",
    "print(message)\n",
    "artist['place_full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('musicbrainz downloader script started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 21,222 unique artists to get details for\n"
     ]
    }
   ],
   "source": [
    "# load the artist IDs from the lastfm scrobble history data set\n",
    "scrobbles = pd.read_csv('data/lastfm_scrobbles.csv', encoding='utf-8')\n",
    "artist_ids = scrobbles['artist_mbid'].dropna().unique()#[1000:1005]\n",
    "message = 'there are {:,} unique artists to get details for'.format(len(artist_ids))\n",
    "log.info(message)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 21,222 artists in 1,015.05 seconds and saved csv\n"
     ]
    }
   ],
   "source": [
    "# get details for each unique artist and turn results into dataframe\n",
    "df = make_artists_df(artist_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-try any failed rows one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 artists to retry\n"
     ]
    }
   ],
   "source": [
    "# get all the row labels missing in the df (due to errors that prevented row creation)\n",
    "missing_row_labels = [ label for label in range(len(artist_ids)) if label not in df.index ]\n",
    "\n",
    "# get the artist mbid for each\n",
    "row_labels_to_retry = sorted(missing_row_labels)\n",
    "artist_ids_to_retry = [ artist_ids[label] for label in row_labels_to_retry ]\n",
    "\n",
    "message = '{} artists to retry'.format(len(artist_ids_to_retry))\n",
    "log.info(message)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 4 artists in 0.14 seconds and saved csv\n"
     ]
    }
   ],
   "source": [
    "# get details for each artist to re-try, and turn results into dataframe\n",
    "df = make_artists_df(artist_ids_to_retry, row_labels_to_retry, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark</td>\n",
       "      <td>489ce91b-6658-3307-9877-795b68554c98</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phantom Planet</td>\n",
       "      <td>1f40c6e1-47ba-4e35-996f-fe6ee5840e62</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Mamas &amp; the Papas</td>\n",
       "      <td>74e50e58-5deb-4b99-93a2-decbb365c07f</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Real Estate</td>\n",
       "      <td>53d70a46-8eb3-4deb-b020-a2c17e8f34ef</td>\n",
       "      <td>Ridgewood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiohead</td>\n",
       "      <td>d840d4b3-8987-4626-928b-398de760cc24</td>\n",
       "      <td>Abingdon-on-Thames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                              place_id  \\\n",
       "0                   Mark  489ce91b-6658-3307-9877-795b68554c98   \n",
       "1         Phantom Planet  1f40c6e1-47ba-4e35-996f-fe6ee5840e62   \n",
       "2  The Mamas & the Papas  74e50e58-5deb-4b99-93a2-decbb365c07f   \n",
       "3            Real Estate  53d70a46-8eb3-4deb-b020-a2c17e8f34ef   \n",
       "4              Radiohead  d840d4b3-8987-4626-928b-398de760cc24   \n",
       "\n",
       "                place  \n",
       "0       United States  \n",
       "1         Los Angeles  \n",
       "2            New York  \n",
       "3           Ridgewood  \n",
       "4  Abingdon-on-Thames  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save to csv and show the head\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "df[['name', 'place_id', 'place']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get full place name for each unique place ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will attempt to get place full names for 2,769 place IDs\n",
      "finished getting place full names from place IDs in 168.22 seconds\n"
     ]
    }
   ],
   "source": [
    "# create a dict where keys are area IDs and values are full place names from MB API\n",
    "unique_place_ids = df['place_id'].dropna().unique()\n",
    "place_ids_names = get_place_full(unique_place_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place</th>\n",
       "      <th>place_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark</td>\n",
       "      <td>489ce91b-6658-3307-9877-795b68554c98</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phantom Planet</td>\n",
       "      <td>1f40c6e1-47ba-4e35-996f-fe6ee5840e62</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles, Los Angeles County, California, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Mamas &amp; the Papas</td>\n",
       "      <td>74e50e58-5deb-4b99-93a2-decbb365c07f</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Real Estate</td>\n",
       "      <td>53d70a46-8eb3-4deb-b020-a2c17e8f34ef</td>\n",
       "      <td>Ridgewood</td>\n",
       "      <td>Ridgewood, Bergen County, New Jersey, United S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiohead</td>\n",
       "      <td>d840d4b3-8987-4626-928b-398de760cc24</td>\n",
       "      <td>Abingdon-on-Thames</td>\n",
       "      <td>Abingdon-on-Thames, Oxfordshire, England, Unit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                              place_id  \\\n",
       "0                   Mark  489ce91b-6658-3307-9877-795b68554c98   \n",
       "1         Phantom Planet  1f40c6e1-47ba-4e35-996f-fe6ee5840e62   \n",
       "2  The Mamas & the Papas  74e50e58-5deb-4b99-93a2-decbb365c07f   \n",
       "3            Real Estate  53d70a46-8eb3-4deb-b020-a2c17e8f34ef   \n",
       "4              Radiohead  d840d4b3-8987-4626-928b-398de760cc24   \n",
       "\n",
       "                place                                         place_full  \n",
       "0       United States                                      United States  \n",
       "1         Los Angeles  Los Angeles, Los Angeles County, California, U...  \n",
       "2            New York                  New York, New York, United States  \n",
       "3           Ridgewood  Ridgewood, Bergen County, New Jersey, United S...  \n",
       "4  Abingdon-on-Thames  Abingdon-on-Thames, Oxfordshire, England, Unit...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each row in dataframe, pull place_full from the place_ids_names dict by place_id\n",
    "df['place_full'] = df['place_id'].map(get_place_full_from_dict)\n",
    "df[['name', 'place_id', 'place', 'place_full']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason MB constructs Irish places' country as \"Ireland, Ireland\" - so clean up the duplicate\n",
    "df['place_full'] = df['place_full'].str.replace('Ireland, Ireland', 'Ireland')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All done - wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 row labels are missing in the df\n",
      "0 rows are missing place_full but have place_id\n"
     ]
    }
   ],
   "source": [
    "# OK, one final check - see how many artist ids did not make it into the final dataframe\n",
    "# first get all the rows missing place_full that have place_id\n",
    "mask = (pd.isnull(df['place_full'])) & (pd.notnull(df['place_id']))\n",
    "rows_missing_place_full = list(df[mask].index)\n",
    "\n",
    "# then get all the row labels missing in the df (due to errors that prevented row creation)\n",
    "missing_row_labels = [ label for label in range(len(artist_ids)) if label not in df.index ]\n",
    "\n",
    "message = '{} row labels are missing in the df'.format(len(missing_row_labels))\n",
    "log.info(message)\n",
    "print(message)\n",
    "message = '{} rows are missing place_full but have place_id'.format(len(rows_missing_place_full))\n",
    "log.info(message)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish by saving the csv and cache files to disk\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "save_cache_to_disk(area_cache, area_cache_filename)\n",
    "save_cache_to_disk(artist_cache, artist_cache_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
